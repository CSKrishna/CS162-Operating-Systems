CS 162
Project 3: Key-Value Store
Design Document


Fill in the following information:

GSI: Alex
Group Number: 10
Aditya Chaturvedi <aditya2013@berkeley.edu>
Duncan McAdam <duncanmcadam@berkeley.edu>
Orzechowski Matthew <morzechowski@berkeley.edu>

1) Please write down any miscellaneous comments or notes for your GSI.

KVCache and KVCacheSet


2) Copy here the declaration of each new or changed `struct' or
`struct' member, global or static variable, `typedef', or
enumeration for KVCache and KVCacheSet.  Briefly identify the purpose of each.

In struct kvcacheentry, we added two struct pointers next and prev to create a linked list so as to iterate 
through all the structs. And then in struct KVCacheset we added a pointed to the first and last cache entry. 

3) How will you ensure that cache accesses are very fast while also implementing the second-chance replacement policy?

The cache accesses will be fast because they involve looking up the entry in a hash table, which is a very fast operation. 
In the case of a cache miss for whatever reason, the operation will take longer, but by using the second-chance replacement 
policy, things that are used less often will be replaced by things that have been used more recently.

Socket Server and Networking
4) Copy here the declaration of each new or changed `struct' or 'struct' member, global or static variable, `typedef', or
enumeration for networking.  Briefly identify the purpose of each.

int thread_count; 
A variable to keep track of how many threads are currently running.
int max_threads; 
We declare an arbitrary value for the maximum amount of threads that can run at a time.
Condition variable reached_max; 
A condition variable that allows us to put any threads that are created past max_threads threads to sleep and have them 
wait until the CV is signaled by an exiting thread.
Lock count_lock; 
A lock to synchronize any access to thread_count, as competeting threads will race for this.


5) To make server_run handle multiple requests simultaneously, you will need to create new threads. However, there is a limit 
on the number of threads you can have running at any one time, so you cannot just fork a new thread for each incoming request. 
How will you achieve this?

To prevent too many threads from running, we first implement a limit on how many threads can run at any given time, and then
if any thread is created after that, it is put to sleep, waiting on the condition variable reached_max. When a thread is
created and there are max_threads threads, that thread is put to sleep until another thread exit and then the sleeping 
the thread is signaled to wake up and begin executing. 


6) Why can you not just fork a new process for every request? What are the two failure modes when this occurs? Note that we 
are asking about forking new processes rather than spawning new threads (which is what is actually done in the project). 

If too many calls to fork() are called, then there may be too many processes and may crash the system or make it run too 
slowly. When this occurs, the threads are simply put to sleep and wait for another thread to signal to any waiting threads to 
begin execution. 


7) Describe how you might test if your socket server's server_run function was working correctly (calling the appropriate 
handle method of kvserver/tpcmaster).
Since server_run initializes the server and then sets up sockets and begins listening on those sockets, we could initialize
two servers to run and then communicate between the two of them. By monitoring our inputs and outputs, we could determine 
whether the socket servers were working correctly, and determine what kind of error occurs if it is not working.


Single Server Key-Value Store
8) Copy here the declaration of each new or changed `struct' or
`struct' member, global or static variable, `typedef', or
enumeration for the single server kv-store.  Briefly identify the purpose of each.

We did not end up needing any additonal data structures for this implementation.


9) Describe at least one end-to-end test you will add. What is the scenario you will test and how will you achieve this in 
the test?

One end to end test we can add is to test sending a value from one server to another server, sending it back, and then 
verifying that they are the same. In this way, we can test if communication both in and out of the server without data 
corruption or incorrect algorithms works.


Distributed Key-Value Store
10) Copy here the declaration of each new or changed `struct' or
`struct' member, global or static variable, `typedef', or
enumeration for the distributed kv-store.  Briefly identify the purpose of each.

in tpc_master.c:
static tpc_state_t state;
This static variable describes the state that the tpc master is currently in (like Commit or Abort).

in kvserver.h:
kvmessage_t *tpc_op;
This points to a malloced kvmessage that stores the put or delete operation that is currently in progress.  It is used both
to determine whether or not a new tpc operation can be started (checking if it is null) as well as doing the stored operation
on a commit.


11) Discuss, in your own words (no copy-pasting), what you will do to handle a PUT request within TPCMaster. 

The tpc master will first set the static state to init and send out the put command to all of the slaves.  Each slave would
recieve the command and store the operation in its tpc_op location.  It then would use kvserver_put_check() to determine 
whether to vote commit or abort.  The master would take the votes and if one of them was abort or time out would set the state
to abort, otherwise commit.  It would then send the commit or abort message to each slave in a loop until it recieved an ack.
The slave would get the message and do the operation stored in tpc_op if the message was a commit.  In both cases the memory
in tpc_op would be cleared so new operations can be done.  The master would finally populate the correct fields in respmsg.


12) Explain, at a high level, how you will modify kvserver_t to allow you to handle two-phase commits. 

When a tpc operation is initiated, each slave will store the operation in its tpc_op field.  This will allow it to do the 
operation after getting a commit.  


13) Explain, at a high level, how you will implement kvserver_rebuild_state. How will you deal with the situation where a 
COMMIT message was put into the log following a PUT or DEL request, but it was not actually committed?

The log will store 1 or 2 messages at a time.  If there is 1 message, then it is just a put or a delete request.  If this is
the case, then the slave will use the message to recreate its tpc_op field that was lost on crash.  When the master sends out
a commit or abort, they can use this field as normal to continue the operation.  
If there are 2 messages, then the first is a put or delete, and the second is an abort or a commit.  If the second message
is a commit, then the slave will use the first message to determine the action it is supposed to do (put or delete) and then
do that action.  If it is abort, then nothing needs to be done, and the slave will respond with an ack when polled again by
the master.


14) In this project, we did not ask you to consider that TPCMaster might ever fail. What would you need to add to handle 
this type of failure?

Similar to the slaves, the master would have a log of its own and a rebuild function.  This rebuild function would certainly
need to be more complicated than the slave rebuild as it would have to take into account the messages from all of the slaves
as well as the client.  


15) This project is optimized for a read heavy system (since writes are so slow). How would you modify this project (while 
keeping all the slaves) for a write heavy system?


Instead of a write through cache for put operations, the master could have a write back cache.  This means that a put
operation could be done much quicker at first.  It could be modified several times without ever having to do a two phase
commit until it is removed from the cache.  